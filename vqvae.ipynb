{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec15a8-2a71-4b5e-9fbc-313a1a6a69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade flax soundfile\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.994\n",
    "%env TF_CPP_MIN_LOG_LEVEL=3\n",
    "!wget -q https://www.gutenberg.org/files/26268/mp3/26268-01.mp3 -O romeo_and_juliet.mp3\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import optax\n",
    "import tqdm\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "\n",
    "from flax import nnx\n",
    "from jax.ad_checkpoint import checkpoint_name as ckpt\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "default_dtype = (\n",
    "    jnp.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "def _down(x: jax.Array) -> jax.Array:\n",
    "    return x.reshape(-1, x.shape[1] // 2, x.shape[2] * 2)\n",
    "\n",
    "\n",
    "def _up(x: jax.Array) -> jax.Array:\n",
    "    return x.reshape(-1, x.shape[1] * 2, x.shape[2] // 2)\n",
    "\n",
    "\n",
    "def gumbel_softmax(\n",
    "    key: jax.Array, \n",
    "    logits: jax.Array, \n",
    "    *,\n",
    "    hard: bool,\n",
    "    temperature: float = 1.0, \n",
    "    axis: int = -1,\n",
    ") -> jax.Array:\n",
    "    logits += jax.random.gumbel(key, logits.shape)\n",
    "    probs = nnx.softmax(logits / temperature, axis=axis)\n",
    "    if not hard:\n",
    "        return probs\n",
    "    index = probs.argmax(axis)\n",
    "    onehot = nnx.one_hot(index, probs.shape[axis], axis=axis, dtype=probs.dtype)\n",
    "    straight_through = probs + jax.lax.stop_gradient(onehot - probs)\n",
    "    return straight_through\n",
    "\n",
    "\n",
    "def reconstruction_loss_fn(preds: jax.Array, batch: jax.Array) -> jax.Array:\n",
    "    p = (batch.shape[1] - preds.shape[1]) // 2\n",
    "    loss = jnp.mean((preds - batch[:, p:-p]) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def diversity_loss_fn(logits: jax.Array, codebook_size: int) -> jax.Array:\n",
    "    avg_probs = nnx.softmax(logits).mean((0, 1))\n",
    "    entropy = -jnp.sum(avg_probs * jnp.log(avg_probs + 1e-7))\n",
    "    perplexity = jnp.exp(entropy)\n",
    "    loss = (codebook_size - perplexity) / codebook_size\n",
    "    return loss\n",
    "\n",
    "\n",
    "def norm(tree) -> jax.Array:\n",
    "    return jnp.linalg.norm(jnp.stack(jax.tree.flatten(jax.tree.map(jnp.linalg.norm, tree))[0]))\n",
    "\n",
    "\n",
    "class ResBlock(nnx.Module):\n",
    "\n",
    "    def __init__(self, dim: int, kernel_size: int, *, rngs: nnx.Rngs):\n",
    "        self.conv = nnx.Conv(dim, 2 * dim, (kernel_size,), param_dtype=default_dtype, rngs=rngs)\n",
    "        self.alpha = nnx.Param(jnp.zeros((), dtype=default_dtype))\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        return x + self.alpha * nnx.glu(ckpt(self.conv(x), \"conv\"))\n",
    "\n",
    "\n",
    "class Backbone(nnx.Module):\n",
    "\n",
    "    def __init__(self, depth: int, dim: int, kernel_size: int, *, rngs: nnx.Rngs):\n",
    "\n",
    "        @nnx.split_rngs(splits=depth)\n",
    "        @nnx.vmap\n",
    "        def create_block(rngs: nnx.Rngs):\n",
    "            return ResBlock(dim, kernel_size, rngs=rngs)\n",
    "\n",
    "        self.p = depth * (kernel_size // 2)\n",
    "        self.blocks = create_block(rngs)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "\n",
    "        @nnx.scan(in_axes=(0, nnx.Carry), out_axes=nnx.Carry)\n",
    "        @nnx.remat(prevent_cse=False, policy=jax.checkpoint_policies.save_only_these_names(\"conv\"))\n",
    "        def forward(block, x):\n",
    "            return block(x)\n",
    "\n",
    "        x = forward(self.blocks, x)\n",
    "        return x[:, self.p:-self.p]\n",
    "\n",
    "\n",
    "class VQVAE(nnx.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        octaves: int,\n",
    "        depth: int,\n",
    "        dim: int,\n",
    "        kernel_size: int,\n",
    "        codebook_size: int,\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "        self.octaves = octaves\n",
    "        self.depth = depth\n",
    "        self.dim = dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.codebook_size = codebook_size\n",
    "        self.rngs = rngs\n",
    "        \n",
    "        self.linear_in = nnx.Linear(1, dim, param_dtype=default_dtype, rngs=rngs)\n",
    "        self.encoder_blocks = [Backbone(depth, dim * 2 ** o, kernel_size, rngs=rngs) for o in range(octaves + 1)]\n",
    "        self.proj = nnx.Linear(dim * 2 ** octaves, codebook_size, param_dtype=default_dtype, rngs=rngs)\n",
    "        self.codebook = nnx.Param(jax.random.normal(rngs.params(), (codebook_size, dim * 2 ** octaves), dtype=default_dtype))\n",
    "        self.decoder_blocks = [Backbone(depth, dim * 2 ** o, kernel_size, rngs=rngs) for o in range(octaves, -1, -1)]\n",
    "        self.linear_out = nnx.Linear(dim, 1, param_dtype=default_dtype, rngs=rngs)\n",
    "        \n",
    "    def encoder(self, x: jax.Array) -> jax.Array:\n",
    "        x = self.linear_in(x)\n",
    "        for backbone in self.encoder_blocks[:-1]:\n",
    "            x = _down(backbone(x))\n",
    "        x = self.encoder_blocks[-1](x)\n",
    "        logits = self.proj(x)\n",
    "        return logits\n",
    "    \n",
    "    def quantizer(self, logits: jax.Array, temperature: float = 1.0) -> jax.Array:\n",
    "        key = self.rngs.gumbel_softmax()\n",
    "        onehots = gumbel_softmax(key, logits, temperature=temperature, hard=True)\n",
    "        codes = onehots @ self.codebook\n",
    "        return codes\n",
    "    \n",
    "    def decoder(self, x: jax.Array) -> jax.Array:\n",
    "        x = self.decoder_blocks[0](x)\n",
    "        for backbone in self.decoder_blocks[1:]:\n",
    "            x = backbone(_up(x))\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "        \n",
    "    def __call__(self, x: jax.Array, temperature: float = 1.0) -> tuple[jax.Array, jax.Array]:\n",
    "        logits = self.encoder(x)\n",
    "        x = self.quantizer(logits, temperature)\n",
    "        x = self.decoder(x)\n",
    "        return x, logits\n",
    "\n",
    "    def valid_length(self, bottleneck: int) -> int:\n",
    "        length = bottleneck\n",
    "        length += (self.kernel_size - 1) * self.depth\n",
    "        for _ in range(self.octaves):\n",
    "            length *= 2\n",
    "            length += (self.kernel_size - 1) * self.depth\n",
    "        return length\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(\n",
    "    model: VQVAE, \n",
    "    optimizer: nnx.Optimizer, \n",
    "    batch: jax.Array,\n",
    "    temperature: float = 1.0,\n",
    ") -> tuple[jax.Array, dict[str, jax.Array]]:\n",
    "    \n",
    "    @nnx.value_and_grad(has_aux=True)\n",
    "    def loss_fn(model):\n",
    "        preds, logits = model(batch)\n",
    "        reconstruction_loss = reconstruction_loss_fn(preds, batch)\n",
    "        diversity_loss = diversity_loss_fn(logits, model.codebook_size)\n",
    "        loss = 100 * reconstruction_loss + 0.1 * diversity_loss\n",
    "        log_dict = dict(\n",
    "            reconstruction_loss=reconstruction_loss,\n",
    "            diversity_loss=diversity_loss,\n",
    "        )\n",
    "        return loss, log_dict\n",
    "\n",
    "    (loss, log_dict), grads = loss_fn(model)\n",
    "    log_dict[\"grad_norm\"] = norm(grads)\n",
    "    optimizer.update(grads)\n",
    "    return loss, log_dict\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def encode(model: VQVAE, batch: jax.Array) -> jax.Array:\n",
    "    return model.encoder(default_dtype(batch)).argmax(-1)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def decode(model: VQVAE, batch: jax.Array) -> jax.Array:\n",
    "    return model.decoder(model.codebook[batch]).astype(jnp.float32)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def roundtrip(model: VQVAE, batch: jax.Array) -> jax.Array:\n",
    "    return decode(model, encode(model, batch))\n",
    "    \n",
    "\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, filename: str, window_size: int, batch_size: int):\n",
    "        self.data, self.sr = soundfile.read(filename)\n",
    "        if self.data.ndim == 1:\n",
    "            self.data = self.data[:, None]\n",
    "        self.windows = np.lib.stride_tricks.sliding_window_view(self.data, window_size, axis=0)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            indices = np.random.randint(len(self.windows), size=self.batch_size)\n",
    "            yield default_dtype(self.windows[indices].transpose(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b115b81-dc6a-4d0e-b60e-17847fb49f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    octaves: int = 6\n",
    "    depth: int = 15\n",
    "    dim: int = 16\n",
    "    kernel_size: int = 3\n",
    "    codebook_size: int = 8192\n",
    "    seed: int = 0\n",
    "    max_grad_norm: float = 1.0\n",
    "    init_lr: float = 1e-4\n",
    "    peak_lr: float = 5e-3\n",
    "    end_lr: float = 1e-4\n",
    "    warmup_steps: int = 100\n",
    "    decay_steps: int = 10_000\n",
    "    weight_decay: float = 0.\n",
    "    data_filename: str = \"romeo_and_juliet.mp3\"\n",
    "    bottleneck_length: int = 64\n",
    "    batch_size: int = 512\n",
    "\n",
    "    \n",
    "def initialize(cfg: Config) -> tuple[VQVAE, nnx.Optimizer, Dataset]:\n",
    "    model = VQVAE(\n",
    "        octaves=cfg.octaves,\n",
    "        depth=cfg.depth,\n",
    "        dim=cfg.dim,\n",
    "        kernel_size=cfg.kernel_size,\n",
    "        codebook_size=cfg.codebook_size,\n",
    "        rngs=nnx.Rngs(cfg.seed),\n",
    "    )\n",
    "    print(f\"{sum(jax.tree.flatten(jax.tree.map(jnp.size, nnx.split(model, nnx.Param, ...)[1]))[0])/1_000_000:.1f}M params\")\n",
    "    optimizer = nnx.Optimizer(\n",
    "        model,\n",
    "        optax.chain(\n",
    "            optax.clip_by_global_norm(cfg.max_grad_norm),\n",
    "            optax.adamw(\n",
    "                optax.warmup_cosine_decay_schedule(\n",
    "                    init_value=cfg.init_lr,\n",
    "                    peak_value=cfg.peak_lr,\n",
    "                    end_value=cfg.end_lr,\n",
    "                    warmup_steps=cfg.warmup_steps,\n",
    "                    decay_steps=cfg.decay_steps,\n",
    "                ),\n",
    "                weight_decay=cfg.weight_decay,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    dataset = Dataset(\n",
    "        cfg.data_filename, \n",
    "        window_size=model.valid_length(cfg.bottleneck_length), \n",
    "        batch_size=cfg.batch_size,\n",
    "    )\n",
    "    return model, optimizer, dataset\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "pprint(cfg)\n",
    "model, optimizer, dataset = initialize(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26c5eb-ceb5-4b9c-8f06-f87273e60b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "progbar = tqdm.trange(cfg.decay_steps, mininterval=1)\n",
    "temps = np.geomspace(2, 0.1, cfg.decay_steps)\n",
    "losses = []\n",
    "try:\n",
    "    for step, batch, temperature in zip(progbar, dataset, temps):\n",
    "        loss, log_dict = train_step(model, optimizer, batch, temperature)\n",
    "        progbar.set_postfix(loss=loss, temperature=temperature, **log_dict, refresh=False)\n",
    "        losses.append(loss.item())\n",
    "finally:\n",
    "    plt.semilogy(losses)\n",
    "    plt.grid(True, which=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7753683-31cd-4ed2-9a23-0c7541128e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original:\")\n",
    "start = dataset.sr * 60 * 45 - 3000  # minutes in. \n",
    "sample = dataset.data[None, start:start+model.valid_length(4096)]\n",
    "display(Audio(sample.squeeze(), rate=dataset.sr))\n",
    "\n",
    "print(\"round-trip:\")\n",
    "prediction = roundtrip(model, sample)\n",
    "display(Audio(prediction.squeeze(), rate=dataset.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbfdc1-3313-4410-90b2-f1485b4ebd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
